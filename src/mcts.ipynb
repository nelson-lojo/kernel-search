{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from exo import proc, DRAM, Procedure, SchedulingError, Memory\n",
    "import exo.query_asts as exo_ast\n",
    "import multiprocessing as mp\n",
    "import concurrent.futures\n",
    "\n",
    "import re\n",
    "import sys\n",
    "from itertools import chain\n",
    "from functools import reduce\n",
    "from typing import Any, Callable, Optional\n",
    "\n",
    "from psutil import Process, cpu_count\n",
    "Process().cpu_affinity(list(range(cpu_count())))\n",
    "\n",
    "sys.setrecursionlimit(10_000)\n",
    "\n",
    "\n",
    "BRANCHING_THRESHOLD: int = 3\n",
    "CONTROL_STRUCTURE = (exo_ast.For, exo_ast.If, exo_ast.Proc)\n",
    "SYMBOL_STRUCTURE = (exo_ast.Read, exo_ast.Reduce, exo_ast.Alloc, exo_ast.Assign)\n",
    "LOOP_SPLIT_SIZES: int = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging and Profiling tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import cProfile\n",
    "\n",
    "def profileit(do_print: bool = False):\n",
    "    def inner(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            prof = cProfile.Profile()\n",
    "            retval = prof.runcall(func, *args, **kwargs)\n",
    "\n",
    "            if do_print:\n",
    "                prof.print_stats(sort=\"cumtime\")\n",
    "            else:\n",
    "                prof.dump_stats(f\"{func.__name__}.profile\")\n",
    "\n",
    "            return retval\n",
    "        return wrapper\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query AST Classes (copied from the docstring)\n",
    "---\n",
    "\n",
    "In this notebook, we work the QAST (as opposed to the LoopIR AST, Memory AST, Parallel AST, C compilation AST, etc.). This is primarily due to ease of programmability, as most features of the code are easily extractable from either a regex or a traversal of the QAST. \n",
    "\n",
    "Exo ast nodes are organized into a hierarchy of dataclasses:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- QueryAST\n",
    "  - `Proc`  ( name : str, args : list[FnArg], assertions : list[Expr],\n",
    "                        body : list[Stmt],  instruction : Optional[str] )\n",
    "  - `Stmt`\n",
    "    - `Assign`    ( name : str,   lhs_type : Type,    idx : list[Expr],\n",
    "                              rhs  : Expr )\n",
    "    - `Reduce`    ( name : str,   lhs_type : Type,    idx : list[Expr],\n",
    "                              rhs  : Expr )\n",
    "    - `WriteConfig` ( config : Config, field : str,\n",
    "                              rhs  : Expr )\n",
    "    - `Pass`      ()\n",
    "    - `If`        ( cond : Expr,  body : list[Stmt],  orelse : list[Stmt] )\n",
    "    - `For`       ( name : str,   lo   : Expr,        hi : Expr,\n",
    "                              body : list[Stmt],  is_par : bool )\n",
    "    - `Alloc`     ( name : str,   type : Type,        memory : Optional[Memory] )\n",
    "    - `Call`      ( proc : str,   args : list[Expr] )\n",
    "    - `WindowStmt`( name : str,   rhs  : Expr )\n",
    "  - `Expr`\n",
    "    - `Read`    ( name : str,   idx  : list[Expr],    type : Type )\n",
    "    - `Const`   ( val  : Any,   type : Type )\n",
    "    - `USub`    ( arg  : Expr,  type : Type )\n",
    "    - `BinOp`   ( op   : str,   lhs  : Expr,\n",
    "                            rhs  : Expr,          type : Type )\n",
    "    - `BuiltIn` ( func : str,   args : list[Expr],    type : Type )\n",
    "    - `WindowExpr`( name : str, idx : list[WAccess],  type : Type )\n",
    "    - `StrideExpr`( name : str, dim : int,            type : Type )\n",
    "    - `ReadConfig`( config : Config, field : str,     type : Type )\n",
    "  - `WAccess`\n",
    "    - `Interval`( lo : Expr, hi : Expr )\n",
    "    - `Point`( pt : Expr )\n",
    "  - `FnArg` ( name : str, type : Type, memory : Optional[Memory] )\n",
    "  - `Type`\n",
    "    - `R`()\n",
    "    - `f16`()\n",
    "    - `f32`()\n",
    "    - `f64`()\n",
    "    - `i8`()\n",
    "    - `i32`()\n",
    "    - `bool`()\n",
    "    - `int`()\n",
    "    - `index`()\n",
    "    - `size`()\n",
    "    - `stride`()\n",
    "    - `tensor`( hi : list[Expr], is_window : bool, type : Type )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tools initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proc(name='generated_operation',\n",
      "     args=[FnArg(name='In',\n",
      "                 type=tensor(hi=[Const(val=16, type=int()),\n",
      "                                 Const(val=16, type=int())],\n",
      "                             is_window=False,\n",
      "                             type=i8()),\n",
      "                 memory=<class 'exo.memory.DRAM'>),\n",
      "           FnArg(name='Weights',\n",
      "                 type=tensor(hi=[Const(val=16, type=int()),\n",
      "                                 Const(val=16, type=int())],\n",
      "                             is_window=False,\n",
      "                             type=i8()),\n",
      "                 memory=<class 'exo.memory.DRAM'>),\n",
      "           FnArg(name='Out',\n",
      "                 type=tensor(hi=[Const(val=16, type=int()),\n",
      "                                 Const(val=16, type=int())],\n",
      "                             is_window=False,\n",
      "                             type=i8()),\n",
      "                 memory=<class 'exo.memory.DRAM'>)],\n",
      "     assertions=[],\n",
      "     body=[For(name='i',\n",
      "               lo=Const(val=0, type=int()),\n",
      "               hi=Const(val=16, type=int()),\n",
      "               body=[For(name='j',\n",
      "                         lo=Const(val=0, type=int()),\n",
      "                         hi=Const(val=16, type=int()),\n",
      "                         body=[For(name='k',\n",
      "                                   lo=Const(val=0, type=int()),\n",
      "                                   hi=Const(val=16, type=int()),\n",
      "                                   body=[Reduce(name='Out',\n",
      "                                                lhs_type=i8(),\n",
      "                                                idx=[Read(name='i',\n",
      "                                                          idx=[],\n",
      "                                                          type=index()),\n",
      "                                                     Read(name='j',\n",
      "                                                          idx=[],\n",
      "                                                          type=index())],\n",
      "                                                rhs=BinOp(op='*',\n",
      "                                                          lhs=Read(name='In',\n",
      "                                                                   idx=[Read(name='i',\n",
      "                                                                             idx=[],\n",
      "                                                                             type=index()),\n",
      "                                                                        Read(name='k',\n",
      "                                                                             idx=[],\n",
      "                                                                             type=index())],\n",
      "                                                                   type=i8()),\n",
      "                                                          rhs=Read(name='Weights',\n",
      "                                                                   idx=[Read(name='k',\n",
      "                                                                             idx=[],\n",
      "                                                                             type=index()),\n",
      "                                                                        Read(name='j',\n",
      "                                                                             idx=[],\n",
      "                                                                             type=index())],\n",
      "                                                                   type=i8()),\n",
      "                                                          type=i8()))],\n",
      "                                   is_par=False)],\n",
      "                         is_par=False)],\n",
      "               is_par=False)],\n",
      "     instruction=None)\n"
     ]
    }
   ],
   "source": [
    "def get_exo_proc() -> Procedure:\n",
    "    @proc\n",
    "    def generated_operation(\n",
    "        In: i8[16, 16] @ DRAM,\n",
    "        Weights: i8[16, 16] @ DRAM,\n",
    "        Out: i8[16, 16] @ DRAM,\n",
    "    ):\n",
    "        for i in seq(0, 16):\n",
    "            for j in seq(0, 16):\n",
    "                for k in seq(0, 16):\n",
    "                    Out[i, j] += In[i, k] * Weights[k, j]\n",
    "\n",
    "    return generated_operation\n",
    "\n",
    "PROC_AST: exo_ast.Proc = get_exo_proc().get_ast() # pyright: ignore[reportAssignmentType]\n",
    "pprint(PROC_AST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def extract_c_code(proc: Procedure) -> str:\n",
    "    \"\"\"Compile the procedure to C code and remove all header information\"\"\"\n",
    "    return proc.c_code_str().split(\"#include <stdlib.h>\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern_from_node(ast: exo_ast.QueryAST):\n",
    "    \"\"\"Produce a \"pattern\" necessary to match this node using normal scheduling operations\"\"\"\n",
    "    match ast:\n",
    "        case exo_ast.For(name=n):\n",
    "            return f\"for {n} in _ : _\"\n",
    "        case _:\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_nest_call(lst, mapping, enable: bool, \n",
    "    threshold: int = BRANCHING_THRESHOLD,\n",
    "    d_type: type[list | set] = list,\n",
    "    reduction = chain\n",
    "    ):\n",
    "    \"\"\"Helper method to enable parallel traversals of the AST\"\"\"\n",
    "    if enable and len(lst) > threshold:\n",
    "        with mp.Pool() as pool:\n",
    "            return d_type(reduction(\n",
    "                *pool.starmap(mapping, [(item, False) for item in lst]\n",
    "            )))\n",
    "    return d_type(reduction(*[mapping(item, can_split=enable) for item in lst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'In': [16, 16], 'Weights': [16, 16], 'Out': [16, 16]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTYPE = \"i8\"\n",
    "def get_names_and_dimensions(proc: Procedure) -> dict[str, list[int]]:\n",
    "    \"\"\"Get all buffers that are defined *somewhere* in the procedure\"\"\"\n",
    "    src_code = str(proc)\n",
    "\n",
    "    matches = re.findall(f'([a-zA-Z_0-9]*): {DTYPE}\\[([^\\]]*)\\]', src_code)\n",
    "\n",
    "    dims = {\n",
    "        name: [ int(d) for d in dims.split(\", \") ]\n",
    "        for name, dims in matches\n",
    "    }\n",
    "\n",
    "    return dims\n",
    "get_names_and_dimensions(get_exo_proc())#, [\"Out\", \"In\", \"Weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AST Traversals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[For(name='i', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[For(name='j', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[For(name='k', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[Reduce(name='Out', lhs_type=i8(), idx=[Read(name='i', idx=[], type=index()), Read(name='j', idx=[], type=index())], rhs=BinOp(op='*', lhs=Read(name='In', idx=[Read(name='i', idx=[], type=index()), Read(name='k', idx=[], type=index())], type=i8()), rhs=Read(name='Weights', idx=[Read(name='k', idx=[], type=index()), Read(name='j', idx=[], type=index())], type=i8()), type=i8()))], is_par=False)], is_par=False)], is_par=False),\n",
       " For(name='j', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[For(name='k', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[Reduce(name='Out', lhs_type=i8(), idx=[Read(name='i', idx=[], type=index()), Read(name='j', idx=[], type=index())], rhs=BinOp(op='*', lhs=Read(name='In', idx=[Read(name='i', idx=[], type=index()), Read(name='k', idx=[], type=index())], type=i8()), rhs=Read(name='Weights', idx=[Read(name='k', idx=[], type=index()), Read(name='j', idx=[], type=index())], type=i8()), type=i8()))], is_par=False)], is_par=False),\n",
       " For(name='k', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[Reduce(name='Out', lhs_type=i8(), idx=[Read(name='i', idx=[], type=index()), Read(name='j', idx=[], type=index())], rhs=BinOp(op='*', lhs=Read(name='In', idx=[Read(name='i', idx=[], type=index()), Read(name='k', idx=[], type=index())], type=i8()), rhs=Read(name='Weights', idx=[Read(name='k', idx=[], type=index()), Read(name='j', idx=[], type=index())], type=i8()), type=i8()))], is_par=False)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_all_blocks(mod: exo_ast.QueryAST, can_split: bool = True) -> list[exo_ast.For | exo_ast.If]:\n",
    "    \"\"\"Produce a list of the For/If nodes in the ast.Module in depth-wise order.\"\"\"\n",
    "    if not isinstance(mod, CONTROL_STRUCTURE):\n",
    "        return [ ]\n",
    "\n",
    "    match mod:\n",
    "        case exo_ast.For(body=b) | exo_ast.If(body=b):\n",
    "            return [mod] + parallel_nest_call(b, find_all_blocks, enable=can_split)\n",
    "        case exo_ast.Proc(body=b):\n",
    "            return parallel_nest_call(b, find_all_blocks, enable=can_split)\n",
    "        case _:\n",
    "            raise ValueError\n",
    "\n",
    "find_all_blocks(PROC_AST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[For(name='i', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[For(name='j', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[For(name='k', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[Reduce(name='Out', lhs_type=i8(), idx=[Read(name='i', idx=[], type=index()), Read(name='j', idx=[], type=index())], rhs=BinOp(op='*', lhs=Read(name='In', idx=[Read(name='i', idx=[], type=index()), Read(name='k', idx=[], type=index())], type=i8()), rhs=Read(name='Weights', idx=[Read(name='k', idx=[], type=index()), Read(name='j', idx=[], type=index())], type=i8()), type=i8()))], is_par=False)], is_par=False)], is_par=False),\n",
       " For(name='j', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[For(name='k', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[Reduce(name='Out', lhs_type=i8(), idx=[Read(name='i', idx=[], type=index()), Read(name='j', idx=[], type=index())], rhs=BinOp(op='*', lhs=Read(name='In', idx=[Read(name='i', idx=[], type=index()), Read(name='k', idx=[], type=index())], type=i8()), rhs=Read(name='Weights', idx=[Read(name='k', idx=[], type=index()), Read(name='j', idx=[], type=index())], type=i8()), type=i8()))], is_par=False)], is_par=False),\n",
       " For(name='k', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[Reduce(name='Out', lhs_type=i8(), idx=[Read(name='i', idx=[], type=index()), Read(name='j', idx=[], type=index())], rhs=BinOp(op='*', lhs=Read(name='In', idx=[Read(name='i', idx=[], type=index()), Read(name='k', idx=[], type=index())], type=i8()), rhs=Read(name='Weights', idx=[Read(name='k', idx=[], type=index()), Read(name='j', idx=[], type=index())], type=i8()), type=i8()))], is_par=False)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_fors(mod: exo_ast.QueryAST, can_split: bool = True) -> list[exo_ast.For]:\n",
    "    \"\"\"Produce a list of the For nodes in the ast.Module in depth-wise order.\"\"\"\n",
    "    all_blocks = find_all_blocks(mod, can_split=can_split)\n",
    "    fors: list[exo_ast.For] = filter(lambda b: isinstance(b, exo_ast.For), all_blocks) # pyright: ignore[reportAssignmentType]\n",
    "    return list(fors)\n",
    "\n",
    "extract_fors(PROC_AST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "union = lambda iter_of_sets: reduce(lambda a, b: a | b, iter_of_sets, set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('i', 'j'), ('j', 'k')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_swappable_loops(ast: exo_ast.QueryAST, can_split: bool = True) -> set[tuple[str, str]]:\n",
    "    \"\"\"Return a set of all swappable for loops\"\"\"\n",
    "    if not isinstance(ast, CONTROL_STRUCTURE):\n",
    "        return set([])\n",
    "\n",
    "    match ast:\n",
    "        case exo_ast.For(name=name, body=[exo_ast.For(name=inner_name)]):\n",
    "            return set([(name, inner_name)]) \\\n",
    "                 | get_swappable_loops(ast.body[0], can_split)\n",
    "        case exo_ast.Proc(body=b) | exo_ast.If(body=b) | exo_ast.For(body=b):\n",
    "            # unfortunately not as simple as the following:\n",
    "            # return parallel_nest_call(b, get_swappable_loops, can_split, d_type=set, reduction=union)\n",
    "            if can_split and len(b) > BRANCHING_THRESHOLD:\n",
    "                with mp.Pool() as pool:\n",
    "                    return union(pool.starmap(get_swappable_loops, \n",
    "                        [ (node, False) for node in b ] \n",
    "                    ))\n",
    "\n",
    "            return union([\n",
    "                get_swappable_loops(node, can_split)\n",
    "                for node in b\n",
    "            ])\n",
    "        case _:\n",
    "            raise ValueError\n",
    "\n",
    "get_swappable_loops(PROC_AST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[For(name='k', lo=Const(val=0, type=int()), hi=Const(val=16, type=int()), body=[Reduce(name='Out', lhs_type=i8(), idx=[Read(name='i', idx=[], type=index()), Read(name='j', idx=[], type=index())], rhs=BinOp(op='*', lhs=Read(name='In', idx=[Read(name='i', idx=[], type=index()), Read(name='k', idx=[], type=index())], type=i8()), rhs=Read(name='Weights', idx=[Read(name='k', idx=[], type=index()), Read(name='j', idx=[], type=index())], type=i8()), type=i8()))], is_par=False)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_innermost_loops(mod: exo_ast.QueryAST, can_split: bool = True) -> list[exo_ast.For]:\n",
    "    \"\"\"Get all loops with no loops inside them\"\"\"\n",
    "    if not isinstance(mod, CONTROL_STRUCTURE):\n",
    "        return [ ]\n",
    "\n",
    "    match mod:\n",
    "        case exo_ast.Proc(body=b) | exo_ast.If(body=b):\n",
    "            return parallel_nest_call(b, find_innermost_loops, enable=can_split)\n",
    "        case exo_ast.For(body=b):\n",
    "            if any(map(lambda n: isinstance(n, exo_ast.For), b)):\n",
    "                return parallel_nest_call(b, find_innermost_loops, enable=can_split)\n",
    "            return [mod]\n",
    "        case _:\n",
    "            raise ValueError\n",
    "\n",
    "find_innermost_loops(PROC_AST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lazy Transform Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from exo.stdlib.scheduling import (\n",
    "    simplify,\n",
    "    unroll_loop,\n",
    "    reorder_loops,\n",
    "    divide_loop,\n",
    "    replace_all,\n",
    "    \n",
    "    stage_mem,\n",
    "    set_memory,\n",
    "    divide_dim,\n",
    "    mult_dim,\n",
    "    unroll_buffer,\n",
    "    # join_loops,\n",
    "    # cut_loop,\n",
    "    # shift_loop,\n",
    "    # mult_loops,\n",
    "    # remove_loop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScheduledProc:\n",
    "    \"\"\"A wrapper class to allow for lazy evaluation of scheduling operations\"\"\"\n",
    "    def __init__(self, exo_sched_func: Callable, args: list = [], kwargs: dict[str, Any] = {}):\n",
    "        self.sched_func = exo_sched_func\n",
    "        self.func_args = args\n",
    "        self.func_kwargs = kwargs\n",
    "\n",
    "    def _apply_transform(self, proc: Procedure) -> Procedure:\n",
    "        func = self.sched_func\n",
    "\n",
    "        return func(\n",
    "            proc, \n",
    "            *self.func_args,\n",
    "            **self.func_kwargs\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"{self.sched_func.__name__}(<proc>, \"\n",
    "          + \", \".join(map(str, self.func_args))\n",
    "          + \", \"\n",
    "          + \", \".join([f\"{key} = {val}\" for key, val in self.func_kwargs.items()])\n",
    "          + \")\"\n",
    "        )\n",
    "\n",
    "    def __call__(self, proc: Procedure) -> Procedure | None:\n",
    "        try:\n",
    "            return self._apply_transform(proc)\n",
    "        except SchedulingError as e:\n",
    "            print(f\"WARNING: Encountered {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid branches logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exo.platforms.rvv import RVV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[reorder_loops(<proc>, j k, ), reorder_loops(<proc>, i j, )]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_loop_reorders(ast: exo_ast.Proc, **kwargs) -> list[ScheduledProc]:\n",
    "    \"\"\"Get all valid loop reordering transforms\"\"\"\n",
    "    loop_pairs = get_swappable_loops(ast)\n",
    "    return [\n",
    "        ScheduledProc(\n",
    "            reorder_loops,\n",
    "            [\" \".join(list(loop_pair))], \n",
    "            {}\n",
    "        ) for loop_pair in loop_pairs\n",
    "    ]\n",
    "\n",
    "get_loop_reorders(PROC_AST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[unroll(<proc>, , ), unroll(<proc>, , ), unroll(<proc>, , )]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_loop_unrolls(ast: exo_ast.Proc, **kwargs) -> list[ScheduledProc]:\n",
    "    \"\"\"Get every possible loop unrolling transform\"\"\"\n",
    "    all_loops = extract_fors(ast)\n",
    "    unrolls = [ ]\n",
    "    for loop in all_loops:\n",
    "        def unroll(proc: Procedure) -> Procedure:\n",
    "            p = unroll_loop(proc, loop.name)\n",
    "            # p = simplify(p)\n",
    "            return p\n",
    "        unrolls.append(ScheduledProc(unroll))\n",
    "\n",
    "    return unrolls\n",
    "\n",
    "get_loop_unrolls(PROC_AST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[split(<proc>, , ), split(<proc>, , ), split(<proc>, , )]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_loop_splits(ast: exo_ast.Proc, **kwargs) -> list[ScheduledProc]:\n",
    "    \"\"\"Get every loop split given `LOOP_SPLIT_SIZES` set earlier in the notebook\"\"\"\n",
    "    lowest_loops = find_innermost_loops(ast)\n",
    "\n",
    "    splits: list[ScheduledProc] = [ ]\n",
    "    for loop in lowest_loops:\n",
    "        if not (isinstance(loop.hi, exo_ast.Const) and isinstance(loop.lo, exo_ast.Const)):\n",
    "            continue # we can't split loops without constant bounds\n",
    "\n",
    "        for split_const in range(LOOP_SPLIT_SIZES, loop.hi.val - loop.lo.val, LOOP_SPLIT_SIZES):\n",
    "            new_loops = [f\"{loop.name}_out\", f\"{loop.name}_in\"]\n",
    "            def split(proc: Procedure) -> Procedure:\n",
    "                p = divide_loop(proc, loop.name, split_const, new_loops, tail=\"cut\")\n",
    "                # p = simplify(p)\n",
    "                return p\n",
    "\n",
    "            splits.append(ScheduledProc(split))\n",
    "\n",
    "    return splits\n",
    "\n",
    "get_loop_splits(PROC_AST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loop_fusions(ast: exo_ast.Proc, **kwargs): raise NotImplementedError\n",
    "    # all_loops = extract_fors(ast)\n",
    "\n",
    "    # fusions = [ ]\n",
    "    # num_loops = len(all_loops)\n",
    "    # for i in range(num_loops):\n",
    "    #     for j in range(i+1, num_loops):\n",
    "    #         loop1 = get_pattern_from_node(all_loops[i])\n",
    "    #         loop2 = get_pattern_from_node(all_loops[j])\n",
    "    #         fusions.append(ScheduledProc(join_loops, [loop1, loop2]))\n",
    "    \n",
    "    # return fusions\n",
    "# fs = get_loop_fusions(PROC_AST)\n",
    "# fs[1](get_exo_proc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,\n",
       " [do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , ),\n",
       "  do_stage(<proc>, , )])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mem_stages(proc: Procedure, **kwargs) -> list[Procedure]:\n",
    "    \"\"\"Stage every identifier outside of every block onto every memory\"\"\"\n",
    "    blocks = find_all_blocks(proc.get_ast()) # pyright: ignore[reportArgumentType]\n",
    "    try:\n",
    "        buffers = get_names_and_dimensions(proc)\n",
    "    except ValueError as _:\n",
    "        return [ ]\n",
    "    \n",
    "\n",
    "    stages = [ ]\n",
    "    for buff_name, dims in buffers.items():\n",
    "        for block in blocks:\n",
    "            for mem in [RVV, DRAM]:\n",
    "\n",
    "                block_pattern = get_pattern_from_node(block)\n",
    "                new_symbol = f\"{buff_name}Staged\"\n",
    "                window_expr = f\"{buff_name}[{','.join([f'0:{end}' for end in dims])}]\"\n",
    "\n",
    "                def do_stage(proc):\n",
    "                    proc = stage_mem(proc, block_pattern, window_expr, new_symbol)\n",
    "                    proc = set_memory(proc, new_symbol, mem)\n",
    "                    # proc = simplify(proc)\n",
    "                    return proc\n",
    "\n",
    "                stages.append(ScheduledProc(do_stage))\n",
    "\n",
    "    return stages\n",
    "e = get_mem_stages(get_exo_proc())\n",
    "len(e), e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[reshape(<proc>, , ), reshape(<proc>, , ), reshape(<proc>, , )]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_buff_reshapes(proc: Procedure, **kwargs):\n",
    "    \"\"\"Get a flattening of every buffer to be of dimension (-1, 4) to eventually work with rvv\"\"\"\n",
    "    try:\n",
    "        buffers = get_names_and_dimensions(proc)\n",
    "    except ValueError as _:\n",
    "        return [ ]\n",
    "\n",
    "    reshapes = [ ]\n",
    "    for buff, dims in buffers.items():\n",
    "        num_flattens = len(dims) - 1\n",
    "        def reshape(proc: Procedure) -> Procedure:\n",
    "            proc = divide_dim(proc, f\"{buff} : _\", len(dims)-1, 4)\n",
    "            for _ in range(num_flattens):\n",
    "                proc = mult_dim(proc, buff, 0, 1)\n",
    "            \n",
    "            # proc = simplify(proc)\n",
    "            return proc\n",
    "\n",
    "        reshapes.append(ScheduledProc(reshape))\n",
    "\n",
    "    return reshapes\n",
    "get_buff_reshapes(get_exo_proc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_buff_unrolls(proc: Procedure) -> list[ScheduledProc]:\n",
    "    \"\"\"Get an unrolling of every buffer that is of shape (-1, 4)\"\"\"\n",
    "    try:\n",
    "        buffers = get_names_and_dimensions(proc)\n",
    "    except ValueError as _:\n",
    "        return [ ]\n",
    "\n",
    "    unrolls = [ ]\n",
    "    for name, dims in buffers.items():\n",
    "        if len(dims) != 2 or dims[1] != 4:\n",
    "            # if the buffer can't be put onto RVV, skip\n",
    "            continue\n",
    "        \n",
    "        unrolls.append(ScheduledProc(unroll_buffer, [name, 0]))\n",
    "    \n",
    "    return unrolls\n",
    "get_buff_unrolls(get_exo_proc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gemmini instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section ended up getting abandoned due to the complexity of dealing with *two* necessary memory staging transforms per output buffer. The problem was simplified to only search for RVV algorithms to improve the chance that a valid algorithm could be found in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exo.platforms.gemmini import (\n",
    "    do_ld_i8_block_id1,\n",
    "    do_ld_i8_vector,\n",
    "    do_ld_i8,\n",
    "\n",
    "    do_matmul_i8,\n",
    "\n",
    "    st_acc_i32,\n",
    "    do_st_acc_i8,\n",
    "\n",
    "    config_ld_i8,\n",
    "    config_ld_i8_id1,\n",
    "    config_matmul,\n",
    "\n",
    ")\n",
    "\n",
    "from exo.API import check_eqv_proc\n",
    "\n",
    "def find_eq_gemmini_subtrees(ast: exo_ast.QueryAST) -> list[exo_ast.QueryAST]:\n",
    "    ...\n",
    "\n",
    "def get_gemmini_insts(_: exo_ast.Proc) -> list[ScheduledProc]:\n",
    "    return [\n",
    "        ScheduledProc(replace_all, [gemmini_inst])\n",
    "        for gemmini_inst in [\n",
    "            # do_ld_i8_block_id1,\n",
    "            # do_matmul_i8\n",
    "\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "ALL_INSTS = [\n",
    "    \"acc_scale\",\n",
    "] + [ # i8 loading config insts\n",
    "    \"config_ld_i8\" + suff\n",
    "    for suff in [\n",
    "        \"\", \"_id1\", \"_id2\", \"_s2_id1\"\n",
    "    ]\n",
    "] + [ # i8 loads\n",
    "    \"do_ld_i8\" + suff # ld_i8_prototype\n",
    "    for suff in [\n",
    "        \"\", \"_id1\", \"_id2\", \"_s2_id1\", \n",
    "        \"_block_id1\", \n",
    "        \"_block_id2\", \n",
    "        \"_vector\",\n",
    "    ]\n",
    "] + [ # i8 block loads (not \"do\")\n",
    "    \"ld_i8_block\" + suff\n",
    "    for suff in [\n",
    "        \"\",\n",
    "        \"_id1\", \"_id1_v2\", \"_id1_s2_v2\",\n",
    "        \"_id2\", \"_id2_v2\", \"_id2_s2_v2\",\n",
    "    ]\n",
    "] + [ # remaining i8 loads (not \"do\")\n",
    "    \"ld_i8\" + suff # this one is the same as do_ld_i8, but with a pass statement\n",
    "    for suff in [\n",
    "        \"\", \"_v2\", \"_s2\",\n",
    "        \"_id1\", \"_id1_v2\", \"_id1_s2_v2\",\n",
    "        \"_id2\", \"_id2_v2\", \"_id2_s2_v2\",\n",
    "        \"_vector\",\n",
    "    ]\n",
    "] + [\n",
    "    \"do_ld_acc_i32\",\n",
    "    \"do_ld_acc_i32_vector\",\n",
    "\n",
    "    \"config_ld_acc_i32_vector\",\n",
    "    \n",
    "    \"ld_acc_i8\",\n",
    "    \"ld_acc_i32\",\n",
    "    \"ld_acc_i32_vector\",\n",
    "    \"ld_acc_i32_vector_v2\",\n",
    "\n",
    "\n",
    "    \"zero_block_id2\",\n",
    "    \n",
    "    \"st_i8\",\n",
    "\n",
    "    \"clamp\",\n",
    "\n",
    "    \"config_st_acc_i8\",\n",
    "    \"do_st_acc_i8\",\n",
    "\n",
    "    \"st_acc_i8\",\n",
    "    \"st_acc_i8_v2\",\n",
    "    \"st_acc_i8_s2_v2\",\n",
    "    \n",
    "    \"st_acc_i32\",\n",
    "    \n",
    "    \"config_zero\",\n",
    "\n",
    "    \"do_zero_i8\",\n",
    "    \"do_zero_i8_vector\",\n",
    "\n",
    "    \"do_zero_acc_i32\",\n",
    "\n",
    "    \"zero_acc_i32_v2\",\n",
    "    \"zero_acc_i32\",\n",
    "    \n",
    "    \n",
    "    \"zero_i8\",\n",
    "    \"zero_i8_v2\",\n",
    "    \"zero_i8_vector\",\n",
    "    \"zero_i8_vector_v2\",\n",
    "    \n",
    "\n",
    "    \"config_matmul\",\n",
    "\n",
    "    \"do_matmul_i8\",\n",
    "    # \"matmul_i8_v2\",\n",
    "    # \"matmul_i8\",\n",
    "\n",
    "    # \"do_matmul_acc_i8\",\n",
    "    # \"matmul_acc_i8_v2\",\n",
    "    # \"matmul_acc_i8\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RVV instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exo.platforms.rvv as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_rvv_ld_st(proc: Procedure) -> Procedure:\n",
    "    return ( replace_all(\n",
    "        replace_all(\n",
    "            proc, \n",
    "            r.rvv_vld_4xf32\n",
    "        )\n",
    "        , r.rvv_vst_4xf32)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[replace_rvv_ld_st(<proc>, , ),\n",
       " replace_all(<proc>, def rvv_vfmacc_1xf32_4xf32(dst: [f32][4] @ RVV, lhs: [f32][1] @ DRAM,\n",
       "                            rhs: [f32][4] @ RVV, vl: size):\n",
       "     # @instr {dst_data} = __riscv_vfmacc_vf_f32m1{dst_data}, {lhs_data}, {rhs_data},{vl});\n",
       "     assert stride(dst, 0) == 1\n",
       "     assert stride(lhs, 0) == 1\n",
       "     assert stride(rhs, 0) == 1\n",
       "     assert vl >= 0\n",
       "     assert vl <= 4\n",
       "     for i in seq(0, vl):\n",
       "         dst[i] += lhs[0] * rhs[i], ),\n",
       " replace_all(<proc>, def rvv_vfmacc_4xf32_4xf32(dst: [f32][4] @ RVV, lhs: [f32][4] @ RVV,\n",
       "                            rhs: [f32][4] @ RVV, vl: size):\n",
       "     # @instr {dst_data} = __riscv_vfmacc_vv_f32m1({dst_data}, {lhs_data}, {rhs_data},{vl});\n",
       "     assert stride(dst, 0) == 1\n",
       "     assert stride(lhs, 0) == 1\n",
       "     assert stride(rhs, 0) == 1\n",
       "     assert vl >= 0\n",
       "     assert vl <= 4\n",
       "     for i in seq(0, vl):\n",
       "         dst[i] += lhs[i] * rhs[i], ),\n",
       " replace_all(<proc>, def rvv_vfmacc_4xf32_1xf32(dst: [f32][4] @ RVV, lhs: [f32][4] @ RVV,\n",
       "                            rhs: [f32][1] @ DRAM, vl: size):\n",
       "     # @instr {dst_data} = __riscv_vfmacc_vf_f32m1{dst_data}, {rhs_data}, {lhs_data},{vl});\n",
       "     assert stride(dst, 0) == 1\n",
       "     assert stride(lhs, 0) == 1\n",
       "     assert stride(rhs, 0) == 1\n",
       "     assert vl >= 0\n",
       "     assert vl <= 4\n",
       "     for i in seq(0, vl):\n",
       "         dst[i] += lhs[i] * rhs[0], )]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rvv_insts(**_) -> list[ScheduledProc]:\n",
    "    return [\n",
    "        ScheduledProc(replace_rvv_ld_st),\n",
    "        ScheduledProc(replace_all, [r.rvv_vfmacc_1xf32_4xf32]),\n",
    "        ScheduledProc(replace_all, [r.rvv_vfmacc_4xf32_4xf32]),\n",
    "        ScheduledProc(replace_all, [r.rvv_vfmacc_4xf32_1xf32]),\n",
    "        # ScheduledProc(replace_all, [r.rvv_broadcast_4xf32]),\n",
    "        # ScheduledProc(replace_all, [r.rvv_broadcast_4xf32_0]),\n",
    "        # ScheduledProc(replace_all, [r.rvv_broadcast_4xf32_scalar]),\n",
    "    ]\n",
    "get_rvv_insts(ast=PROC_AST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate all valid branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def generated_operation(In: i8[16, 16] @ DRAM, Weights: i8[16, 16] @ DRAM,\n",
       "                        Out: i8[16, 16] @ DRAM):\n",
       "    for i in seq(0, 16):\n",
       "        for k in seq(0, 16):\n",
       "            for j in seq(0, 16):\n",
       "                Out[i, j] += In[i, k] * Weights[k, j]\n",
       "```"
      ],
      "text/plain": [
       "<exo.API.Procedure at 0x7f24c3f77670>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_exo_tsfs(proc: Procedure, include_simplify: bool = True, debug: bool = False):\n",
    "    \"\"\"Get a list of all possible transforms that can be applied to a procedure\"\"\"\n",
    "    root_ast: exo_ast.Proc = proc.get_ast() # pyright: ignore[reportAssignmentType]\n",
    "    tsfs: list[ScheduledProc] = [ ]\n",
    "\n",
    "    for expansion in [\n",
    "        get_loop_reorders,\n",
    "        get_mem_stages,\n",
    "        get_buff_reshapes,\n",
    "        get_loop_unrolls,\n",
    "        get_loop_splits,\n",
    "        # get_gemmini_insts,\n",
    "        get_rvv_insts,\n",
    "    ]:\n",
    "\n",
    "        new_tsfs = expansion(\n",
    "            ast = root_ast,\n",
    "            proc = proc,\n",
    "        )\n",
    "\n",
    "        if debug:\n",
    "            print(f\"\\t  Found {len(new_tsfs)} cases of {expansion.__name__}\")\n",
    "\n",
    "        tsfs.extend(new_tsfs)\n",
    "\n",
    "    if include_simplify:\n",
    "        tsfs.append(ScheduledProc(simplify))\n",
    "\n",
    "    return tsfs\n",
    "\n",
    "p = get_exo_proc()\n",
    "tsf = get_all_exo_tsfs(get_exo_proc())[0]\n",
    "tsf(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from heapq import heappop, heappush, heapify\n",
    "from importlib import reload\n",
    "from random import random\n",
    "\n",
    "from evaluate import PersistentQueue, PersistentHeap, PersistentMap, QUEUE_FILE, ARTIFACT_DIR\n",
    "\n",
    "LOGFILE = f\"{ARTIFACT_DIR}/tree_search.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stub functions for future work\n",
    "def apply_scheduled_proc(sp: ScheduledProc, p: Procedure): # possibly needed for parallelism\n",
    "    return sp(p), p\n",
    "\n",
    "def estimate_cost(proc: Procedure) -> float:\n",
    "    # This would be where we add the secret sauce\n",
    "    # e.g. : AlphaDev as a value network or some \n",
    "    #        AST-native heuristic\n",
    "\n",
    "    # for now, we guess a random cost since that seems to \n",
    "    #   visit nodes faster (at least visually)\n",
    "    return random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Persistence Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Search state tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisitationTrackerClassic:\n",
    "\n",
    "    def __init__(self, starting_nodes):\n",
    "        self.underlying = [ ]\n",
    "        self.see(starting_nodes)\n",
    "\n",
    "    def visit(self) -> \"node\":\n",
    "        return heappop(self.underlying)\n",
    "\n",
    "    def see(self, nodes) -> None:\n",
    "        for node in nodes:\n",
    "            heappush(self.underlying, node)\n",
    "\n",
    "    def hasitems(self) -> bool:\n",
    "        return len(self.underlying) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEAP_SPLIT_THRESH = 5\n",
    "\n",
    "class VisitationTracker:\n",
    "\n",
    "    def __init__(self, starting_nodes: list = [ ], directory: str = f\"{ARTIFACT_DIR}/visitation/\"):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        self.dir = directory\n",
    "        self.heads_file = self.dir + f\"/heads.pkl\"\n",
    "        self.branch_file = self.dir + f\"/branches.pkl\"\n",
    "        self.perst_heap = PersistentHeap(self.heads_file, overwrite=False)\n",
    "        self.branches = PersistentMap(self.branch_file, overwrite=False)\n",
    "\n",
    "        self.see(starting_nodes)\n",
    "\n",
    "    def visit(self) -> \"node\":\n",
    "        out_head = self.perst_heap.get()\n",
    "        if out_head is None:\n",
    "            return None\n",
    "\n",
    "        branch_to_update = self.branches.get(out_head)\n",
    "        if branch_to_update is None:\n",
    "            return out_head\n",
    "\n",
    "        new_head = branch_to_update.get()\n",
    "\n",
    "        if new_head is None:\n",
    "            self.branches.remove(out_head)\n",
    "        else:\n",
    "            self.perst_heap.put(new_head)\n",
    "\n",
    "        return out_head\n",
    "\n",
    "    def see(self, nodes: list) -> None:\n",
    "        add_nodes = nodes[:]\n",
    "\n",
    "        if len(add_nodes) > HEAP_SPLIT_THRESH:\n",
    "            while len(add_nodes) > 0:\n",
    "                self.see(add_nodes[:HEAP_SPLIT_THRESH])\n",
    "                add_nodes = add_nodes[HEAP_SPLIT_THRESH:]\n",
    "            return\n",
    "\n",
    "        if len(nodes) == 0:\n",
    "            return\n",
    "\n",
    "        new_branch = PersistentHeap(\n",
    "            filename=self._get_new_file(f\"{len(add_nodes)}\"),\n",
    "            overwrite=True\n",
    "        )\n",
    "\n",
    "        heapify(add_nodes)\n",
    "        head = heappop(add_nodes)\n",
    "        new_branch.put(*add_nodes)\n",
    "    \n",
    "        self.perst_heap.put(head)\n",
    "        self.branches.put(key=head, value=new_branch)\n",
    "\n",
    "    def _get_new_file(self, suffix: str = \"\") -> str:\n",
    "        return f\"{self.dir}/{str(hash(random()))}_{suffix}.pkl\"\n",
    "\n",
    "    def hasitems(self) -> bool:\n",
    "        tmp = self.perst_heap.get()\n",
    "        we_have_an_item = tmp is not None\n",
    "        self.perst_heap.put(tmp)\n",
    "        return we_have_an_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(num: int):\n",
    "    for filename in [LOGFILE, QUEUE_FILE]:\n",
    "        chkpt_fname = os.path.dirname(filename) + \\\n",
    "            f\"/{num}_\" + os.path.basename(filename)\n",
    "        os.system(f\"cp -r \\\"{filename}\\\" \\\"{chkpt_fname}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.system(f\"rm -rf {ARTIFACT_DIR}/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_queue = PersistentQueue(persistence_file=QUEUE_FILE, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_log(entry: str, write_to: Optional[str] = None):\n",
    "    if write_to is not None and write_to != \"\":\n",
    "        with open(write_to, 'a') as f:\n",
    "            f.write(entry.strip() + \"\\n\")\n",
    "    else:\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_branch(\n",
    "        parent: Procedure,\n",
    "        child: Optional[Procedure] = None,\n",
    "        failed: bool = False,\n",
    "        write_to: Optional[str] = LOGFILE\n",
    "    ):\n",
    "\n",
    "    parent_hash = hash(extract_c_code(parent))\n",
    "    if child is None:\n",
    "        write_log(f\"# {parent_hash} revisited\", write_to=write_to)\n",
    "        return\n",
    "    child_hash = hash(extract_c_code(child))\n",
    "    write_log(\n",
    "        f\"{parent_hash} -> {child_hash}\" + (\" # failed\" if failed else \"\"),\n",
    "        write_to=write_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_proc(proc: Procedure) -> str:\n",
    "    return str(proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_proc(proc_str: str) -> Procedure:\n",
    "    prelude = \"\"\"from __future__ import annotations\n",
    "from exo import proc, DRAM\n",
    "from exo.platforms.rvv import *\n",
    "@proc\\n\"\"\"\n",
    "# prelude = \"\"\n",
    "    total_code = prelude + proc_str\n",
    "\n",
    "    with open(\"my_out.py\", \"w\") as f:\n",
    "        f.write(total_code)\n",
    "\n",
    "    import my_out\n",
    "    reload(my_out)\n",
    "    return my_out.generated_operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Core Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expanding node 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Encountered find: failed to find matches\n",
      "Pattern: Out : _\n",
      "WARNING: Encountered find: failed to find matches\n",
      "Pattern: Out : _\n",
      "WARNING: Encountered find: failed to find matches\n",
      "Pattern: Out : _\n",
      "expanding node 2\n",
      "WARNING: Encountered <<<unknown directive>>>: Loops i and j at /workspaces/project/src/my_out.py:7:4 cannot be reordered.\n",
      "WARNING: Encountered <<<unknown directive>>>: expected loop 'i1' to have constant bounds\n",
      "WARNING: Encountered <<<unknown directive>>>: expected loop 'i1' to have constant bounds\n",
      "WARNING: Encountered <<<unknown directive>>>: expected loop 'i1' to have constant bounds\n",
      "WARNING: Encountered <<<unknown directive>>>: expected loop 'i1' to have constant bounds\n",
      "WARNING: Encountered <<<unknown directive>>>: expected loop 'i1' to have constant bounds\n",
      "WARNING: Encountered <<<unknown directive>>>: expected loop 'i1' to have constant bounds\n",
      "WARNING: Encountered <<<unknown directive>>>: expected loop 'i1' to have constant bounds\n",
      "expanding node 3\n",
      "WARNING: Encountered <<<unknown directive>>>: Loops i and j at /workspaces/project/src/my_out.py:7:4 cannot be reordered.\n"
     ]
    }
   ],
   "source": [
    "# @profileit(do_print=True)\n",
    "def search_procs(\n",
    "        proc: Procedure,\n",
    "        debug: bool = False,\n",
    "        compile_to_c: bool = True,\n",
    "        parallel_transforms: bool = False,\n",
    "        checkpoint_freq: int = int(1e2)\n",
    "    ):\n",
    "    \"\"\"Perform a randomized breadth-first search of all possible sequences of transformations of the procedure\"\"\"\n",
    "    seen_procs = PersistentMap(\n",
    "        filename=f\"{ARTIFACT_DIR}/seen_procs.pkl\",\n",
    "        overwrite=False\n",
    "    )\n",
    "\n",
    "    journey = VisitationTracker([(0, 0, serialize_proc(proc))])\n",
    "    nodes_expanded: int = 0\n",
    "    checkpoints_made: int = 0\n",
    "\n",
    "    while journey.hasitems():\n",
    "        nodes_expanded = (nodes_expanded + 1) % checkpoint_freq\n",
    "        print(f\"expanding node {nodes_expanded}\")\n",
    "        if nodes_expanded == 0:\n",
    "            checkpoints_made += 1\n",
    "            # save_checkpoint(num=checkpoints_made * checkpoint_freq)\n",
    "\n",
    "\n",
    "        last_estim, last_tie_breaker, p_str = journey.visit() #heappop(visitation_heap)\n",
    "        p = deserialize_proc(p_str)\n",
    "        code = extract_c_code(p)\n",
    "\n",
    "        if seen_procs.get(key=code, default=None): # this is a previously visited node, skip expansion\n",
    "            log_branch(p, None)\n",
    "            continue\n",
    "\n",
    "        seen_procs.put(key=code, value=p_str)\n",
    "        evaluation_queue.put(code)\n",
    "\n",
    "        all_tsfs = get_all_exo_tsfs(p)\n",
    "\n",
    "\n",
    "        if not parallel_transforms:\n",
    "            new_procs = [ ]\n",
    "            for tsf in all_tsfs:\n",
    "                try:\n",
    "                    np = tsf(p) # this calculation is the performance bottleneck (100% serial in #tsfs)\n",
    "                    # np_code = str(np) if not compile_to_c else extract_c_code # this cuts memory usage back only one depth\n",
    "                except:\n",
    "                    log_branch(p, None, failed=True)\n",
    "                    continue\n",
    "\n",
    "                new_procs.append((np, tsf))\n",
    "        else:\n",
    "            with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "                new_procs = list( # this doesn't work\n",
    "                    executor.map(apply_scheduled_proc, [[t, p] for t in all_tsfs])\n",
    "                )\n",
    "                # the un-pickle-ing of the return values in the above doesn't work:\n",
    "                #    - When pickling, the symbols get packed in as they \n",
    "                #        understand themselves (i.e. <thing>.__getstate__)\n",
    "                #    - The problem is that old objects don't expect to be a \n",
    "                #        part of a more complex construct and so return a\n",
    "                #        __main__.<thing> value for that\n",
    "                #    - However, for us, it's often more complicated -- including\n",
    "                #        imports and submodules, e.g. exo.<thing> due to exo \n",
    "                #        importing <thing> all the way up to its root __init__\n",
    "                #    - So when pickle tries to write to what <thing> thinks it is\n",
    "                #        and finds that that name doesn't actually exist in our\n",
    "                #        namespace, it errors\n",
    "\n",
    "        hops = [ ]\n",
    "        for np, tsf in new_procs:\n",
    "\n",
    "            if np is None:\n",
    "                log_branch(p, None, failed=True)\n",
    "                continue # filter out failed transforms\n",
    "\n",
    "            log_branch(p, np)\n",
    "\n",
    "            # We break ties with randomness\n",
    "            hop = (estimate_cost(np), last_estim + random(), serialize_proc(np))\n",
    "            # heappush(visitation_heap, hop)\n",
    "            hops.append(hop)\n",
    "\n",
    "        journey.see(hops)\n",
    "\n",
    "    return list(seen_procs.get_raw().values())\n",
    "\n",
    "\n",
    "procs = search_procs(get_exo_proc())\n",
    "procs, len(procs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exo's scheduling API (copied from docs, but very outdated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Top-level Python function decorator\n",
    "\n",
    "1. `@proc` - decorates a Python function which is parsed and compiled as Exo. Replaces\n",
    "   the function with a `Procedure` object.\n",
    "2. `@instr` - same as `@proc`, but accepts a hardware instruction as a format string.\n",
    "3. `@config` - decorates a Python class which is parsed and compiled as an Exo\n",
    "   configuration object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Procedure object methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Introspection operations**\n",
    "\n",
    "- `.name()` returns the procedure name.\n",
    "- `.check_effects()` forces Exo to run effect checking on the procedure.\n",
    "- `.show_effects()` prints the effects of the procedure.\n",
    "- `.show_effect(stmt)` prints the effect of the `stmt` in the procedure.\n",
    "- `.is_instr()` returns `true` if the procedure has a hardware instruction string.\n",
    "- `.get_instr()` returns the hardware instruction string.\n",
    "- `.get_ast()` returns a `QAST`, which is an AST representation suitable for\n",
    "  introspection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Execution / interpretation operations**\n",
    "\n",
    "- `.compile_c(directory, filename)` compiles the procedure into C and stores\n",
    "  in `filename` in the `directory`.\n",
    "- `.interpret(**args)` runs Exo interpreter on the procedure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Scheduling operations on Procedure objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loop related operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `.split(loop, split_const, iter_vars, tail='guard', perfect=False)`\n",
    "  - Splits `loop` into an outer and an inner loop. The inner loop bound is `split_const` and the outer and inner loop names are specified by a list of strings `iter_vars`. If `perfect` is True, it will not introduce a tail case. `tail` specifies the tail strategies, where the options are `guard`, `cut`, and `cut_and_guard`.\n",
    "- `.fuse_loop(loop1, loop2)`\n",
    "  - Fuses two adjacent loops with a common iteration variable.\n",
    "- `.partition_loop(loop, num)`\n",
    "  - Partitions `loop` into two loops, the first running between `0` and `num` and the second between `num+1` and `loop`'s original bound.\n",
    "- `.reorder(loop1, loop2)`\n",
    "  - Reorders two nested loops. `loop2` should be nested directly inside `loop1`. `loop1` will be nested inside `loop2` after this operation.\n",
    "- `.unroll(loop)`\n",
    "  - Unrolls the loop. The loop needs to have a constant bound.\n",
    "- `.fission_after(stmt, n_lifts=1)`\n",
    "  - Fissions the `n_lifts` number of loops around the `stmt`. The fissioned loops around the `stmt` need to be directly nested with each other and the statements before and after the `stmt` should not have any allocation dependencies.\n",
    "- `.remove_loop(loop)`\n",
    "  - Replaces the loop with its body if the body is idempotent. The system must be able to prove that the loop runs at least once.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Buffer related operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `.reuse_buffer(buf1, buf2` \n",
    "  - Reuses a buffer `buf1` in the use site of `buf2` and removes the allocation of `buf2`\n",
    "- `.inline_window(win_stmt)`\n",
    "  - Removes the window statement `win_stmt`, which is an alias to the window, and inlines the windowing in its use site\n",
    "- `.expand_dim(stmt, alloc_dim, indexing)`\n",
    "  - Expands the dimension of the allocation statement `stmt` with dimension `alloc_dim` of indexing `indexing`\n",
    "- `.bind_expr(new_name, expr)`\n",
    "  - Binds the right hand side expression `expr` to a newly allocated buffer named `new_name`\n",
    "- `.stage_mem(win_expr, new_name, stmt_start, stmt_end=None)`\n",
    "  - Stages the buffer `win_expr` to the new window expression `new_name` in statement block (`stmt_start` to `stmt_end`), and adds an initialization loop and a write-back loop\n",
    "- `.rearrange_dim(alloc, dimensions)`\n",
    "  - Takes an allocation statement and a list of integers to map the dimension. It rearranges the dimensions of `alloc` in `dimension` order. E.g., if `alloc` were `foo[N,M,K]` and the `dimension` were `[2,0,1]`, it would become `foo[K,N,M]` after this operation.\n",
    "- `.lift_alloc(alloc, n_lifts=1, keep_dims=False)`\n",
    "  - Lifts the allocation statement `alloc` out of `n_lifts` number of scopes. If and For statements are the only statements in Exo which introduce a scope. When lifting the allocation out of a for loop, it will expand its dimension to the loop bound if `keep_dims` is True.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Config related operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `.bind_config(expr, config, field)`\n",
    "  - Binds the right hand side `expr` to `config.field`. It will replace the use site of `expr` with `config.field` and introduces a config statement of `config.field = expr`.\n",
    "- `.configwrite_root(config, field, expr)`\n",
    "  - Inserts the config statement `config.field = expr` in the beginning of the procedure.\n",
    "- `.configwrite_after(stmt, config, field, expr)`\n",
    "  - Inserts the config statement `config.field = expr` after `stmt`.\n",
    "- `.delete_config(stmt)`\n",
    "  - Deletes the configuration statement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Other scheduling operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `.add_assertion(assertion)`\n",
    "  - Asserts the truth of the expression `assertion` at the beginning of the procedure.\n",
    "- `.lift_if(if, n_lifts=1)`\n",
    "  - Lifts the if statement `if` out of `n_lifts` number of scopes. This is similar to `reorder()`, but for if statements.\n",
    "- `.eliminate_dead_code(stmt)`\n",
    "  - Eliminates `if` statement if condition is always True or False. Eliminates `for` statement if condition is always False.\n",
    "- `.delete_pass()`\n",
    "  - Deletes a `Pass` statement in the procedure.\n",
    "- `.reorder_stmts(stmt1, stmt2)`\n",
    "  - Reorder two adjacent statements `stmt1` and `stmt2`. After this operation, the order will be `stmt2` `stmt1`.\n",
    "  - `.reorder_before(stmt)`\n",
    "    - Move the statement `stmt` before the previous statement. This is a shorthand for `reorder_stmts()`.\n",
    "- `.replace(subproc, stmt)`\n",
    "  - Replace the statement with a call to `subproc`. This operation is one of our contributions and is explained in detail in the paper.\n",
    "- `.replace_all(subproc)`\n",
    "  - Eagerly replace every matching statement with a call to `subproc`.\n",
    "- `.inline(call_site)`\n",
    "  - Inline the function call.\n",
    "- `.is_eq(another_proc)`\n",
    "  - Returns True if `another_proc` is equivalent to the procedure.\n",
    "- `.call_eqv(eqv_proc, call_site)`\n",
    "  - Replace the function call statement of `call_site` with a call to an equivalent procedure `eqv_proc`.\n",
    "- `.repeat(directive, *args)`\n",
    "  - Continue to run the directive until it fails. The directive and its arguments are given separately, e.g. `proc.repeat(Procedure.inline, \"proc_to_inline(_)\")`\n",
    "- `.simplify()`\n",
    "  - Simplify the code in the procedure body. Tries to reduce expressions to constants and eliminate dead branches and loops. Uses branch conditions to simplify expressions inside the branches.\n",
    "- `.rename(new_name)`\n",
    "  - Rename this procedure to `new_name`.\n",
    "- `.make_instr(instr_string)`\n",
    "  - Converts this procedure to an instruction procedure with instruction `instr_string`.\n",
    "- `.partial_eval(*args, **kwargs)`\n",
    "  - Specializes this procedure to the given argument values.\n",
    "- `.set_precision(name, type)`\n",
    "  - Sets the precision type of `name` to `type`.\n",
    "- `.set_window(name, is_window)`\n",
    "  - If `is_window` is True, it sets the buffer `name` to window type, instead of a tensor type.\n",
    "- `.set_memory(name, mem_type)`\n",
    "  - Sets a buffer `name`'s memory type to `mem_type`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
